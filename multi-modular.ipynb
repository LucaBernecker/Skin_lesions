{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f34e3fd6-e867-470d-b58d-95cc5abbefe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dx\n",
       " nv       6705\n",
       " mel      1113\n",
       " bkl      1099\n",
       " bcc       514\n",
       " akiec     327\n",
       " vasc      142\n",
       " df        115\n",
       " Name: count, dtype: int64,\n",
       " dx\n",
       " nv       1430\n",
       " mel      1430\n",
       " bkl      1430\n",
       " bcc      1430\n",
       " akiec    1430\n",
       " vasc     1430\n",
       " df       1430\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(\"/Users/lucabernecker/PHD_UiT/Skin_lesions/HAM10000_metadata.csv\")\n",
    "\n",
    "# Check class distribution in the 'dx' column\n",
    "class_counts = metadata['dx'].value_counts()\n",
    "\n",
    "# Calculate the average class size\n",
    "avg_class_size = int(class_counts.mean())\n",
    "\n",
    "# Oversample minority classes to match the average class size\n",
    "balanced_metadata = pd.concat(\n",
    "    [\n",
    "        \n",
    "        resample(metadata[metadata['dx'] == label], \n",
    "                 replace=True,  # Enable replacement for oversampling\n",
    "                 n_samples=avg_class_size, \n",
    "                 random_state=42)\n",
    "        for label in class_counts.index\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Check new class distribution after oversampling\n",
    "balanced_class_counts = balanced_metadata['dx'].value_counts()\n",
    "\n",
    "# Output class distributions\n",
    "class_counts, balanced_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b499be-88f1-4cda-9b47-781f113d0c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lesion_id      image_id  dx    dx_type   age     sex localization\n",
      "3835  HAM_0000474  ISIC_0030099  nv  follow_up  45.0  female         hand\n",
      "8367  HAM_0000597  ISIC_0030654  nv      histo  35.0  female      abdomen\n",
      "8203  HAM_0007585  ISIC_0032347  nv      histo  35.0  female         back\n",
      "8168  HAM_0005902  ISIC_0027285  nv      histo  40.0  female         foot\n",
      "6747  HAM_0004380  ISIC_0026251  nv      histo  30.0  female         face\n",
      "        lesion_id      image_id  dx    dx_type   age  sex  localization\n",
      "3835  HAM_0000474  ISIC_0030099   5  follow_up  45.0    0             8\n",
      "8367  HAM_0000597  ISIC_0030654   5      histo  35.0    0             0\n",
      "8203  HAM_0007585  ISIC_0032347   5      histo  35.0    0             2\n",
      "8168  HAM_0005902  ISIC_0027285   5      histo  40.0    0             6\n",
      "6747  HAM_0004380  ISIC_0026251   5      histo  30.0    0             5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['dx', 'sex', 'localization']\n",
    "import numpy as np\n",
    "print(balanced_metadata.head())\n",
    "import pandas as pd\n",
    "label_encoders = {}\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    balanced_metadata[col] = le.fit_transform(balanced_metadata[col])\n",
    "    label_encoders[col] = le  # Store the encoder for inverse transformations if needed\n",
    "\n",
    "\n",
    "print(balanced_metadata.head())\n",
    "data = balanced_metadata\n",
    "data['age'] = data['age'].fillna(data['age'].mean())\n",
    "print(np.isnan(data[\"sex\"]).sum())  # Check metadata\n",
    "print(np.isnan(data[\"localization\"]).sum())  # Check images\n",
    "print(np.isnan(data[\"age\"]).sum())  # Check labels\n",
    "print(np.isnan(data[\"dx\"]).sum())  # Check labels\n",
    "print(len(np.unique(data['dx'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b04028f-5693-40a9-a32c-35524e7d2047",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b313ad-23bc-45d1-ac5b-9e1154cb5769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 10:36:25.406265: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-01-08 10:36:25.406286: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-01-08 10:36:25.406292: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2025-01-08 10:36:25.406307: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-08 10:36:25.406315: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, BatchNormalization, Concatenate, Lambda, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "\n",
    "def MLP(input_shape_demo):\n",
    "    inputs = Input(shape=input_shape_demo)  # Input layer for metadata\n",
    "    x = Dense(64, activation='relu')(inputs)  # First dense layer\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu')(x) \n",
    "    x = Dropout(0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Model(inputs=inputs, outputs=x)  # Return the full MLP model\n",
    "\n",
    "def CNN(input_shape):\n",
    "    # Input for the original scale\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Downscale the input image\n",
    "    scale_small = Lambda(lambda x: tf.image.resize(x, (input_shape[0] // 2, input_shape[1] // 2)))(input_layer)\n",
    "\n",
    "    # ResNet50 backbone for the original scale\n",
    "    base_model_original = ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        name=\"resnet50_original\"  # Unique name for the original scale model\n",
    "    )\n",
    "    x_original = base_model_original(input_layer)\n",
    "    x_original = Flatten()(x_original)\n",
    "    x_original = BatchNormalization()(x_original)\n",
    "\n",
    "    # ResNet50 backbone for the smaller scale\n",
    "    base_model_small = ResNet50(\n",
    "        input_shape=(input_shape[0] // 2, input_shape[1] // 2, input_shape[2]),\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        name=\"resnet50_small\"  # Unique name for the smaller scale model\n",
    "    )\n",
    "    x_small = base_model_small(scale_small)\n",
    "    x_small = Flatten()(x_small)\n",
    "    x_small = BatchNormalization()(x_small)\n",
    "\n",
    "    # Concatenate features from both scales\n",
    "    combined_features = Concatenate()([x_original, x_small])\n",
    "    x = BatchNormalization()(combined_features)\n",
    "    x = Dense(1024, activation=\"relu\",kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # Create the final model\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Input layers for metadata and images\n",
    "input_meta = Input(shape=(3,))  # Metadata input (age, sex, localization)\n",
    "input_image = Input(shape=(450, 450, 3))  # Image input\n",
    "\n",
    "# CNN model for image processing\n",
    "cnn_model = CNN(input_shape=(450, 450, 3))  # Create the CNN model\n",
    "x2_out = cnn_model(input_image)  # Pass image input to the CNN model\n",
    "\n",
    "# MLP model for metadata processing\n",
    "mlp_model = MLP(input_shape_demo=(3,))  # Create the MLP model\n",
    "x1_out = mlp_model(input_meta)  # Pass metadata input to the MLP model\n",
    "\n",
    "# Concatenate the outputs of both models\n",
    "combined_input = Concatenate()([x1_out, x2_out])\n",
    "\n",
    "# Apply Dense layers after concatenation\n",
    "x = Dense(128, activation=\"relu\",kernel_regularizer=l2(0.01))(combined_input)\n",
    "x = Dropout(0.2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation=\"relu\",kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# Output layer (softmax for multi-class classification)\n",
    "output = Dense(len(np.unique(data['dx'])), activation=\"softmax\")(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=[input_meta, input_image], outputs=output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d61bf-763b-46cf-8062-53424d66a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucabernecker/anaconda3/envs/tf-macos/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-01-08 10:36:29.436738: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  51/2002\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56:12\u001b[0m 2s/step - accuracy: 0.0832 - loss: 26.6583    "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import Sequence\n",
    "data = balanced_metadata\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, image_dir, batch_size, augment=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(dataframe))\n",
    "        self.augment = augment  # Flag to enable/disable augmentation\n",
    "        self.scaler = MinMaxScaler()  # Initialize scaler for metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indices\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_data = self.dataframe.iloc[batch_indices]\n",
    "        \n",
    "        # Process inputs (e.g., images) and labels\n",
    "        X_images = np.array([\n",
    "            self.load_image(os.path.join(self.image_dir, f\"{image_id}.jpg\"))\n",
    "            for image_id in batch_data['image_id']\n",
    "        ], dtype=np.float32)  # Cast to float32 for consistency\n",
    "        \n",
    "        if self.augment:\n",
    "            X_images = self.augment_images(X_images)  # Apply augmentation\n",
    "        \n",
    "        X_meta = batch_data[['age', 'sex', 'localization']].values.astype(np.float32)  # Ensure float32\n",
    "        X_meta = self.scaler.fit_transform(X_meta)  # Scale metadata\n",
    "        \n",
    "        # Prepare labels\n",
    "        y = batch_data['dx'].values\n",
    "        y = to_categorical(y, num_classes=7)\n",
    "        \n",
    "        return (X_meta, X_images), y\n",
    "    \n",
    "    def load_image(self, image_path):\n",
    "        img = tf.keras.preprocessing.image.load_img(image_path, target_size=(450, 450))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        return img\n",
    "\n",
    "    def augment_images(self, images):\n",
    "        augmented_images = []\n",
    "        for img in images:\n",
    "            # Apply random augmentations using tf.image\n",
    "            img = tf.image.random_flip_left_right(img)  # Random horizontal flip\n",
    "            img = tf.image.random_flip_up_down(img)  # Random vertical flip\n",
    "            img = tf.image.random_brightness(img, max_delta=0.1)  # Random brightness adjustment\n",
    "            img = tf.image.random_contrast(img, lower=0.8, upper=1.2)  # Random contrast adjustment\n",
    "            img = tf.image.random_saturation(img, lower=0.8, upper=1.2)  # Random saturation adjustment\n",
    "            augmented_images.append(img)\n",
    "        return np.array(augmented_images, dtype=np.float32)\n",
    "\n",
    "\n",
    "# Image directory (replace this with the actual path where images are stored)\n",
    "image_dir = \"/Users/lucabernecker/PHD_UiT/Skin_lesions/HAM10000_images_part_1\"\n",
    "\n",
    "# Hyperparameters\n",
    "train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 4\n",
    "input_shape_demo = (3,)  # For metadata (age, sex, localization)\n",
    "input_shape = (450, 450, 3)  # For image data\n",
    "\n",
    "# Create the training and validation generators\n",
    "train_generator = DataGenerator(\n",
    "    dataframe=train_df,\n",
    "    image_dir=image_dir,\n",
    "    batch_size=batch_size,\n",
    "    augment=True  \n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    dataframe=val_df,\n",
    "    image_dir=image_dir,\n",
    "    batch_size=batch_size,\n",
    "    augment=False  \n",
    ")\n",
    "\n",
    "# Create the model\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, clipvalue=1.0)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    validation_data=val_generator, \n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Optionally, print the training history\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181605be-76e2-4aa1-b6e8-491a3601d318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd01ed-1e79-49cd-bd93-d14b24f1dc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
